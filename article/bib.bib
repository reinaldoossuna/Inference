Automatically generated by Mendeley Desktop 1.19.3
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Escalera1997,
author = {Escalera, Arturo De and Moreno, Luis E and Salichs, Miguel Angel},
file = {:home/rossuna/Documents/RoboND/Inference/29400760.pdf:pdf},
number = {6},
pages = {848--859},
title = {{Road Traffic Sign Detection and Classification}},
volume = {44},
year = {1997}
}
@inproceedings{Houben-IJCNN-2013,
author = {Houben, Sebastian and Stallkamp, Johannes and Salmen, Jan and Schlipsing, Marc and Igel, Christian},
booktitle = {International Joint Conference on Neural Networks},
number = {1288},
series = {1},
title = {{Detection of Traffic Signs in Real-World Images: The {\{}G{\}}erman {\{}T{\}}raffic {\{}S{\}}ign {\{}D{\}}etection {\{}B{\}}enchmark}},
year = {2013}
}
@article{YannLeCun1998,
author = {LeCun, Yann and Bottou, Leon and Bengio, Yoshua and Haffner, Patrick},
title = {{Gradient-Based Learning Applied to Document Recognition}},
url = {http://ieeexplore.ieee.org/document/726791/{\#}full-text-section},
year = {1998}
}
@article{Stallkamp2012,
abstract = {Traffic signs are characterized by a wide variability in their visual appearance in real-world environments. For example, changes of illumination, varying weather conditions and partial occlusions impact the perception of road signs. In practice, a large number of different sign classes needs to be recognized with very high accuracy. Traffic signs have been designed to be easily readable for humans, who perform very well at this task. For computer systems, however, classifying traffic signs still seems to pose a challenging pattern recognition problem. Both image processing and machine learning algorithms are continuously refined to improve on this task. But little systematic comparison of such systems exist. What is the status quo? Do today's algorithms reach human performance? For assessing the performance of state-of-the-art machine learning algorithms, we present a publicly available traffic sign dataset with more than 50,000 images of German road signs in 43 classes. The data was considered in the second stage of the German Traffic Sign Recognition Benchmark held at IJCNN 2011. The results of this competition are reported and the best-performing algorithms are briefly described. Convolutional neural networks (CNNs) showed particularly high classification accuracies in the competition. We measured the performance of human subjects on the same data-and the CNNs outperformed the human test persons. {\textcopyright} 2012 Elsevier Ltd.},
author = {Stallkamp, J. and Schlipsing, M. and Salmen, J. and Igel, C.},
doi = {10.1016/j.neunet.2012.02.016},
file = {:home/rossuna/Documents/RoboND/Inference/stallkamp2012.pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
keywords = {Benchmarking,Convolutional neural networks,Machine learning,Traffic sign recognition},
pages = {323--332},
publisher = {Elsevier Ltd},
title = {{Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition}},
url = {http://dx.doi.org/10.1016/j.neunet.2012.02.016},
volume = {32},
year = {2012}
}
@article{Lim2017,
author = {Lim, Kwangyong and Hong, Yongwon and Choi, Yeongwoo and Byun, Hyeran},
doi = {10.1371/journal.pone.0173317},
file = {:home/rossuna/Documents/RoboND/Inference/lim2017.pdf:pdf},
isbn = {1111111111},
pages = {1--22},
title = {{Real-time traffic sign recognition based on a general purpose GPU and deep-learning}},
year = {2017}
}
@article{Ciresan2012,
author = {Cire≈üan, Dan and Meier, Ueli and Masci, Jonathan and Schmidhuber, J{\"{u}}rgen},
doi = {10.1016/j.neunet.2012.02.023},
file = {:home/rossuna/Documents/RoboND/Inference/10.1016@j.neunet.2012.02.023.pdf:pdf},
issn = {0893-6080},
journal = {Neural Networks},
keywords = {deep neural networks,image classification},
pages = {333--338},
publisher = {Elsevier Ltd},
title = {{Multi-column deep neural network for traffic sign classification}},
url = {http://dx.doi.org/10.1016/j.neunet.2012.02.023},
volume = {32},
year = {2012}
}
@article{Iino2014,
abstract = {We propose a deep convolutional neural network ar- chitecture codenamed Inception that achieves the new state of the art for classification and detection in the Im- ageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the compu- tational budget constant. To optimize quality, the architec- tural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular in- carnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
archivePrefix = {arXiv},
arxivId = {1409.4842},
author = {Iino, Nami and Takamatsu, Wataru and Iino, Akinaru and Iizuka, Yasuki and Okino, Shigeki},
doi = {10.1109/CVPR.2015.7298594},
eprint = {1409.4842},
isbn = {9781467369640},
issn = {10636919},
keywords = {GoogleLeNet},
mendeley-tags = {GoogleLeNet},
pmid = {24920543},
title = {{Going Deeper with Convolutions}},
year = {2014}
}
